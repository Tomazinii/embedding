from langchain_google_vertexai import VertexAI
from langchain.output_parsers import StructuredOutputParser
from langchain.prompts import PromptTemplate
from langchain.schema import OutputParserException
from langchain.output_parsers import ResponseSchema
import pandas as pd
import json
import threading
from concurrent.futures import ThreadPoolExecutor

# üîπ Configura√ß√£o do modelo VertexAI
model = VertexAI(model_name="gemini-1.5-flash", project="ufg-prd-energygpt")

# üîπ Leitura do CSV e concatena√ß√£o das colunas
arquivo_csv = "/workspaces/tcc/data.csv"
df = pd.read_csv(arquivo_csv)
df['concatenado'] = df.apply(lambda row: ' | '.join(row.astype(str)), axis=1)
lista = df['concatenado'].tolist()  # Pegando apenas os primeiros 4 para teste

# üîπ Defini√ß√£o do esquema de sa√≠da esperado
response_schemas = [
    ResponseSchema(name="query", description="Pergunta jur√≠dica clara e objetiva."),
    ResponseSchema(name="resposta", description="Resumo conciso da decis√£o judicial."),
    ResponseSchema(name="trecho_referencia", description="Parte exata do documento que fundamenta a resposta."),
    ResponseSchema(name="n√∫mero", description="Metadado do ac√≥rd√£o: n√∫mero"),
    ResponseSchema(name="link", description="Metadado do ac√≥rd√£o: link"),
    ResponseSchema(name="processo", description="Metadado do ac√≥rd√£o: processo"),
    ResponseSchema(name="relator", description="Metadado do ac√≥rd√£o: relator"),
    ResponseSchema(name="data_julgamento", description="Metadado do ac√≥rd√£o data_julgamento."),
]

parser = StructuredOutputParser.from_response_schemas(response_schemas)
format_instructions = parser.get_format_instructions()

# üîπ Prompt formatado
prompt_template = PromptTemplate(
    input_variables=["jurisprudencia"],
    template="""
    **Instru√ß√µes:**  
    Dado uma jurisprud√™ncia, gere uma query relevante para o contexto jur√≠dico, incluindo:

    1. **Query**: Pergunta jur√≠dica clara e objetiva.  
    2. **Resposta**: Resumo conciso da decis√£o judicial.  
    3. **Trecho de refer√™ncia**: Parte exata do documento que fundamenta a resposta.  
    4. **Fonte**: Link para o ac√≥rd√£o e seus metadados (n√∫mero, relator, turma, data de julgamento e publica√ß√£o).  

    **Formato de sa√≠da esperado:**  
    {format_instructions}

    **Jurisprud√™ncia:**  
    {jurisprudencia}
    """
)

lock = threading.Lock()
output_list = []  # Buffer para armazenar os resultados

# üîπ Fun√ß√£o para processar cada item em paralelo
def process_item(idx, value):
    formatted_prompt = prompt_template.format(
        jurisprudencia=value,
        format_instructions=format_instructions
    )

    try:
        response = model.invoke(formatted_prompt)
        # print(f"Resposta do modelo ({idx}):", response)  # Debug
        parsed_output = parser.parse(response)
        
        with lock:
            output_list.append(parsed_output)  # Adiciona no buffer
        
        print(f"‚úî Intera√ß√£o {idx} gravada no buffer.")

    except OutputParserException as e:
        print(f"‚ùå Erro ao processar item {idx}: {e}")

# üîπ Processamento paralelo
try:
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(process_item, idx, value) for idx, value in enumerate(lista)]
        for future in futures:
            future.result()  # Aguarda execu√ß√£o e captura erros

except Exception as e:
    print("‚ùå Erro geral no processamento:", e)

# üîπ Escrevendo no JSON corretamente
with open("teste-lines.json", "w", encoding="utf-8") as json_file:
    json.dump(output_list, json_file, ensure_ascii=False, indent=4)  # Indentado para melhor visualiza√ß√£o

print("‚úÖ Processamento finalizado. Resultados em 'output.json'.")
